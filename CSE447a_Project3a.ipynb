{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pus1uEsM8yxz"
      },
      "source": [
        "# Project 3a: Self-Attention and Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGkqXVfs8yxz",
        "outputId": "ca871b90-1985-4728-b99a-14461bef405c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# Install required packages\n",
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xS6uPVlX8yx0"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsJxO8au8yx0"
      },
      "source": [
        "## 1.1: Implementing Self-Attention from Scratch\n",
        "\n",
        "This assignment is adapted from the code by Yegor Kuznetsov, Liwei Jiang, and Jaehun Jung."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6shmyoQ8yx1"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2yrA6M028yx1"
      },
      "outputs": [],
      "source": [
        "######################################################\n",
        "#  The following code is given to you.\n",
        "######################################################\n",
        "\n",
        "\n",
        "def MHA_wrapper(query, key, value, n_heads=1, causal=False):\n",
        "    \"\"\"\n",
        "    This is a wrapper around the PyTorch implementation of multi-head attention.\n",
        "    You will use this implementation to compare to your implementation for code testing.\n",
        "    \"\"\"\n",
        "    assert query.shape == key.shape == value.shape\n",
        "    _, n_tok, n_embd = query.shape\n",
        "\n",
        "    query = query.transpose(0, 1)\n",
        "    key = key.transpose(0, 1)\n",
        "    value = value.transpose(0, 1)\n",
        "\n",
        "    in_proj_weight = torch.eye(n_embd, dtype=key.dtype, device=key.device).repeat(\n",
        "        (3, 1)\n",
        "    )\n",
        "    out_proj_weight = torch.eye(n_embd, dtype=key.dtype, device=key.device)\n",
        "\n",
        "    attn_mask = None\n",
        "    if causal:\n",
        "        attn_mask = torch.tril(\n",
        "            torch.ones(n_tok, n_tok, dtype=bool, device=key.device)\n",
        "        ).logical_not()\n",
        "\n",
        "    out, _ = F.multi_head_attention_forward(\n",
        "        query,\n",
        "        key,\n",
        "        value,\n",
        "        n_embd,\n",
        "        n_heads,\n",
        "        in_proj_weight=in_proj_weight,\n",
        "        in_proj_bias=None,\n",
        "        bias_k=None,\n",
        "        bias_v=None,\n",
        "        add_zero_attn=False,\n",
        "        dropout_p=0,\n",
        "        out_proj_weight=out_proj_weight,\n",
        "        out_proj_bias=None,\n",
        "        attn_mask=attn_mask,\n",
        "        need_weights=False,\n",
        "    )\n",
        "\n",
        "    return out.transpose(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "v4VjiUts8yx1"
      },
      "outputs": [],
      "source": [
        "######################################################\n",
        "#  The following code is given to you.\n",
        "######################################################\n",
        "\n",
        "# use cpu for now\n",
        "DEVICE = \"cpu\"\n",
        "\n",
        "# make these bigger if you want a stricter test of your code\n",
        "part1_n_tok = 10\n",
        "part1_n_emb = 6\n",
        "\n",
        "# generate fixed pseudo-random Q,K,V for testing attn function\n",
        "torch.manual_seed(447)\n",
        "\n",
        "# Initialize random testing Q,K,V\n",
        "part1_key = torch.randn(1, part1_n_tok, part1_n_emb)\n",
        "part1_value = torch.randn(1, part1_n_tok, part1_n_emb)\n",
        "part1_query = torch.randn(1, part1_n_tok, part1_n_emb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuILLScb8yx1"
      },
      "source": [
        "## Step 0: Set up the projections for attention.\n",
        "**You will complete the following code blocks denoted by `TODO:`.** For now you don't need to implement anything here, as you go through the following steps, you will keep coming back to this cell and fill in your implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b9ddabd8d7c4616b34b5146c9a3f57bc",
          "grade": false,
          "grade_id": "cell-452a25f05b3731e0",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "eR1yIIcX8yx1"
      },
      "outputs": [],
      "source": [
        "def init_qkv_proj(n_embd: int):\n",
        "    \"\"\"\n",
        "    This function is given to you.\n",
        "    :return: A tuple of length 3 containing the projections for Q, K, V.\n",
        "    \"\"\"\n",
        "    return (\n",
        "        nn.Linear(n_embd, n_embd),\n",
        "        nn.Linear(n_embd, n_embd),\n",
        "        nn.Linear(n_embd, n_embd),\n",
        "    )\n",
        "\n",
        "def self_attention(Q, K, V, n_heads=1, causal=True):\n",
        "    \"\"\"\n",
        "    Self-attention block.\n",
        "\n",
        "    Note: You will keep coming back to this cell and fill in more of this function\n",
        "    after completing each of the following steps! Don't forget to re-run this\n",
        "    cell each time you change it. Make sure that once you're done, all the testing\n",
        "    cells should work.\n",
        "\n",
        "    :return: A tensor containing the result of the self-attention operation.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    assert Q.shape == K.shape == V.shape\n",
        "    B, n_tok, n_embd = Q.shape\n",
        "    print(f\"Initial Shapes - Q: {Q.shape}, K: {K.shape}, V: {V.shape}\")\n",
        "\n",
        "    # Step 3 -- split heads - if using multihead attention\n",
        "    if n_heads > 1:\n",
        "        Q, K, V = split_heads(Q, n_heads), split_heads(K, n_heads), split_heads(V, n_heads)\n",
        "        print(f\"After splitting heads - Q: {Q.shape}, K: {K.shape}, V: {V.shape}\")\n",
        "\n",
        "    scores = pairwise_similarities(Q, K)\n",
        "    print(f\"Raw attention scores shape: {scores.shape}\")\n",
        "    # Compute attention scores\n",
        "    scores = attn_scaled(scores, n_embd, n_heads)\n",
        "\n",
        "    print(f\"Scaled attention scores shape: {scores.shape}\")\n",
        "\n",
        "    # Step 2 -- create and apply the causal mask to attention\n",
        "    # Apply causal masking\n",
        "    if causal:\n",
        "        mask = make_causal_mask(n_tok)\n",
        "        print(f\"Causal mask shape: {mask.shape}\")\n",
        "        scores = apply_causal_mask(mask, scores)\n",
        "        print(f\"Masked attention scores shape: {scores.shape}\")\n",
        "\n",
        "    # Step 1 normalize scores and compute outputs\n",
        "    probs = attn_softmax(scores)\n",
        "    print(f\"Softmax probabilities shape: {probs.shape}\")\n",
        "    y = compute_outputs(probs, V)\n",
        "    print(f\"Weighted sum of values shape: {y.shape}\")\n",
        "\n",
        "\n",
        "    # Step 3 -- merge heads.\n",
        "    if n_heads > 1:\n",
        "        y = merge_heads(y)\n",
        "\n",
        "    # output should have the same shape as input\n",
        "    assert y.shape == (B, n_tok, n_embd)\n",
        "    print(f\"Final output shape: {y.shape}\")\n",
        "    return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN5ISQwV8yx1"
      },
      "source": [
        "## Step 1: Implement the core components of attention.\n",
        "\n",
        "Note that a self attention block consists of the following computations:\n",
        "\n",
        "Given a set of query vectors $Q$, key vectors $K$, and value vectors $V$,\n",
        "\n",
        "Compute the raw attention scores $A$ as:\n",
        "$$ A = \\frac{1}{\\sqrt{d_{\\text{head}}}}QK^T $$\n",
        "\n",
        "Apply a softmax to the scaled scores to get the attention weights:\n",
        "$$ A = \\texttt{softmax} (A) $$\n",
        "\n",
        "Compute the output vectors by taking a weighted sum of the value vectors, weighted by the attention weights:\n",
        "$$ O = AV $$\n",
        "\n",
        "Note that $d_{\\text{head}}$ is the dimensionality of the feature vectors i.e. query, key, and value vectors and is given by $\\frac{d_{\\text{model}}}{n_{\\text{heads}}}$, where $d_{\\text{model}}$ is the embedding dimension of the model and $n_{\\text{heads}}$ is the number of attention heads.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9LHw-fs8yx1"
      },
      "source": [
        "Useful tips:\n",
        "- You can use the `@` operator to perform matrix multiplication. Alternatively, you can use the `torch.matmul` function.\n",
        "- For the batched cases, for e.g., you have a tensor X of shape (B, m, n) and another tensor Y of shape (B, n, m), then X@Y performs the matrix multiplication for each of the batch elements, giving you a tensor of shape (B, m, m).\n",
        "- You can use the `transpose` method to transpose matrices in pytorch. If you have a tensor X of shape (B, n, m), then X.transpose(-2, -1) gives you a tensor of shape (B, m, n).\n",
        "- You might find the `F.softmax` function useful. Check the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html) for more details.\n",
        "- Softmax is applied along the last dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqYSSCUe8yx2"
      },
      "source": [
        "**You will complete the following code blocks denoted by `TODO:`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7494548dfc26db5544b8ca7c0cf6989f",
          "grade": false,
          "grade_id": "cell-92dccd6159197a28",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "IgNeJwse8yx2"
      },
      "outputs": [],
      "source": [
        "def pairwise_similarities(Q, K):\n",
        "    \"\"\"\n",
        "    Dot product attention is computed via the dot product between each query and each key.\n",
        "\n",
        "    Inputs:\n",
        "    - Q: torch.Tensor, shape (B, n_tok, n_embd) or (B, n_heads, n_tok, n_embd) containing the queries, where B is the batch size, n_heads is the number of attention heads, n_tok is the number of tokens, and n_embd is the embedding dimension.\n",
        "    - K: torch.Tensor, shape (B, n_tok, n_embd) or (B, n_heads, n_tok, n_embd) containing the keys, where B is the batch size, n_heads is the number of attention heads, n_tok is the number of tokens, and n_embd is the embedding dimension.\n",
        "\n",
        "    :return: The raw attention scores, A = QK^T.\n",
        "    \"\"\"\n",
        "    # transpose k, swap the last 2 dimensions to prepare for dot product\n",
        "    K_transpose = K.transpose(-2,-1)\n",
        "    # compute dot product QK'T\n",
        "    A = torch.matmul(Q, K_transpose)\n",
        "\n",
        "    return A\n",
        "\n",
        "def attn_scaled(A, d_model: float, n_heads: float):\n",
        "    \"\"\"\n",
        "    Scale the raw attention scores.\n",
        "    Inputs:\n",
        "    - A: torch.Tensor, shape (B, n_tok, n_tok) or (B, n_heads, n_tok, n_tok) containing the raw attention scores, where B is the batch size, n_heads is the number of attention heads, n_tok is the number of tokens.\n",
        "    - d_model: int, the embedding dimension.\n",
        "    - n_heads: int, the number of attention heads.\n",
        "    :return: Scaled raw attention scores.\n",
        "\n",
        "    \"\"\"\n",
        "    # comput the size of each head\n",
        "    d_head = d_model / n_heads\n",
        "\n",
        "    # scale the attention scores\n",
        "    A_scaled = A / (d_head ** 0.5)\n",
        "\n",
        "    return A_scaled\n",
        "\n",
        "def attn_softmax(A):\n",
        "    \"\"\"\n",
        "    Normalize the scaled raw attention scores with softmax.\n",
        "    Inputs:\n",
        "    - A: torch.Tensor, shape (B, n_tok, n_tok) or (B, n_heads, n_tok, n_tok) containing the scaled raw attention scores, where B is the batch size, n_heads is the number of attention heads, n_tok is the number of tokens.\n",
        "    :return: Normalized attention scores, A' = softmax(A).\n",
        "    \"\"\"\n",
        "    A_normalized = torch.nn.functional.softmax(A, dim=-1)\n",
        "    return A_normalized\n",
        "\n",
        "def compute_outputs(A, V):\n",
        "    \"\"\"\n",
        "    Get outputs as a weighted sum of values by attention scores, using matrices.\n",
        "    Inputs:\n",
        "    - A: torch.Tensor, shape (B, n_tok, n_tok) or (B, n_heads, n_tok, n_tok) containing the normalized attention scores, where B is the batch size, n_heads is the number of attention heads, n_tok is the number of tokens.\n",
        "    - V: torch.Tensor, shape (B, n_tok, n_embd) or (B, n_heads, n_tok, n_embd) containing the value vectors, where B is the batch size, n_heads is the number of attention heads, n_tok is the number of tokens, and n_embd is the embedding dimension.\n",
        "    :return: weighted sum of values by attention scores.\n",
        "    \"\"\"\n",
        "    # matrix multiplication to compute the weighted sum\n",
        "    outputs  = torch.matmul(A, V)\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Sa9bxYv8yx2"
      },
      "source": [
        "## Test 1: Building Single-headed Self-attention without Masking\n",
        "\n",
        "Implement lines denoted by `Step 1` in `self-attention()`, and run the following test code to verify your implementation produces close enough results to the PyTorch implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmUI9Opz8yx2",
        "outputId": "8a9ee607-4095-48d7-8c9c-0dba1b4327f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Shapes - Q: torch.Size([1, 10, 6]), K: torch.Size([1, 10, 6]), V: torch.Size([1, 10, 6])\n",
            "Raw attention scores shape: torch.Size([1, 10, 10])\n",
            "Scaled attention scores shape: torch.Size([1, 10, 10])\n",
            "Softmax probabilities shape: torch.Size([1, 10, 10])\n",
            "Weighted sum of values shape: torch.Size([1, 10, 6])\n",
            "Final output shape: torch.Size([1, 10, 6])\n",
            "max diff: 1.1920928955078125e-07\n"
          ]
        }
      ],
      "source": [
        "######################################################\n",
        "#  The following code is given to you. DO NOT MODIFY.\n",
        "######################################################\n",
        "\n",
        "out_A = self_attention(part1_query, part1_key, part1_value, n_heads=1, causal=False)\n",
        "out_B = MHA_wrapper(part1_query, part1_key, part1_value, n_heads=1, causal=False)\n",
        "assert out_A.shape == out_B.shape == part1_query.shape\n",
        "\n",
        "print(\"max diff:\", (out_A - out_B).abs().max().item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gnbF6e58yx2"
      },
      "source": [
        "Max difference should be very small, our reference implementation gets a difference of the order of 1e-7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuied-ov8yx2"
      },
      "source": [
        "## Step 2: Implement causal masking for language modeling.\n",
        "\n",
        "Note that for language modeling, since we are predicting the next token at every step, we cannot attend to future tokens. Therefore, we need to apply a causal mask to the attention scores, which is a lower triangular matrix, i.e., all the values above the diagonal are set to zero. Hence, the model can attend to the current and past tokens only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDOn_t_48yx2"
      },
      "source": [
        "Useful tips:\n",
        "\n",
        "- Note that the mask is applied to the attention scores **before** the softmax operation.\n",
        "- A 0 raw attention score (pre-softmax) doesn't mean that after applying softmax it will also be 0! Think what score should be used to represent a raw attention score so that when softmaxed it will be 0.\n",
        "- You might find the `masked_fill` method useful. Check the [documentation](https://pytorch.org/docs/stable/generated/torch.Tensor.masked_fill.html) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-SQNAGX8yx2"
      },
      "source": [
        "**You will complete the following code blocks denoted by `TODO:`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "add8173a9470c5d0c95e195cfd7bc3ae",
          "grade": false,
          "grade_id": "cell-58647279b9ee6bba",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "hWrbzJMV8yx2"
      },
      "outputs": [],
      "source": [
        "def make_causal_mask(n_tok: int):\n",
        "    \"\"\"\n",
        "    Create a mask matrix that masks future context for the attention.\n",
        "    Inputs:\n",
        "    - n_tok: int, the number of tokens in the sequence.\n",
        "    :return: A mask matrix which is a tensor of shape (n_tok, n_tok)\n",
        "    \"\"\"\n",
        "\n",
        "    # lower triangular matrix\n",
        "    mask = torch.tril(torch.ones(n_tok, n_tok))\n",
        "    return mask\n",
        "\n",
        "def apply_causal_mask(mask, A):\n",
        "\n",
        "    \"\"\"\n",
        "    Apply mask to attention.\n",
        "    Inputs:\n",
        "    - mask: torch.Tensor, shape (n_tok, n_tok) containing the causal mask.\n",
        "    - A: torch.Tensor, shape (B, n_tok, n_tok) or (B, n_heads, n_tok, n_tok) containing the attention scores, where B is the batch size, n_heads is the number of attention heads, n_tok is the number of tokens.\n",
        "    :return: A masked attention matrix.\n",
        "    \"\"\"\n",
        "    # make sure it is same device\n",
        "    mask = mask.to(A.device)\n",
        "\n",
        "    # apply the mask to A by setting names positions to -inf\n",
        "    A_masked = A.masked_fill(mask == 0, float('-inf'))\n",
        "    return A_masked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9A9p5Th8yx2"
      },
      "source": [
        "## Test 2: Adding Causal Masks\n",
        "\n",
        "Implement lines denoted by `Step 2` in `self-attention()`, and run the following test code to verify your implementation produces close enough results to the PyTorch implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0bXiy778yx2",
        "outputId": "061a869c-3631-4647-cea4-334f34dd865e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Shapes - Q: torch.Size([1, 10, 6]), K: torch.Size([1, 10, 6]), V: torch.Size([1, 10, 6])\n",
            "Raw attention scores shape: torch.Size([1, 10, 10])\n",
            "Scaled attention scores shape: torch.Size([1, 10, 10])\n",
            "Causal mask shape: torch.Size([10, 10])\n",
            "Masked attention scores shape: torch.Size([1, 10, 10])\n",
            "Softmax probabilities shape: torch.Size([1, 10, 10])\n",
            "Weighted sum of values shape: torch.Size([1, 10, 6])\n",
            "Final output shape: torch.Size([1, 10, 6])\n",
            "max diff: 5.960464477539063e-08\n"
          ]
        }
      ],
      "source": [
        "out_A = self_attention(part1_query, part1_key, part1_value, n_heads=1, causal=True)\n",
        "out_B = MHA_wrapper(part1_query, part1_key, part1_value, n_heads=1, causal=True)\n",
        "assert out_A.shape == out_B.shape == part1_query.shape\n",
        "\n",
        "print(\"max diff:\", (out_A - out_B).abs().max().item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWT1vS8q8yx2"
      },
      "source": [
        "The max difference should be very small, our reference implementation gets a difference of the order of 1e-7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9broRBdr8yx2"
      },
      "source": [
        "## Step 3: Implement multi-head attention.\n",
        "\n",
        "Recall from the lecture that multi-head attention is implemented by running self-attention independently on each head and then concatenating the results. Specifically, we use the following steps:\n",
        "\n",
        "1. Split the queries, keys, and values into multiple heads.\n",
        "$$ Q = [Q_1, Q_2, \\ldots, Q_{n_{\\text{heads}}}], K = [K_1, K_2, \\ldots, K_{n_{\\text{heads}}}], V = [V_1, V_2, \\ldots, V_{n_{\\text{heads}}}] $$\n",
        "where $n_{\\text{heads}}$ is the number of heads. This is done by simply splitting the embedding dimension into $n_{\\text{heads}}$ chunks.\n",
        "\n",
        "2. Run self-attention independently on each head.\n",
        "$$ O_i = \\text{self\\_attention}(Q_i, K_i, V_i, n_{\\text{heads}}=n_{\\text{heads}}, causal=causal) $$\n",
        "for $i=1, 2, \\ldots, n_{\\text{heads}}$.\n",
        "Note that you don't actually need to call the self-attention function separately for each head. If your implementation is correct, you should be able to perform a single call to self_attention with the split Q, K, and V and get the same result.\n",
        "\n",
        "3. Concatenate the results of the heads.\n",
        "$$ O = \\text{concat}(O_1, O_2, \\ldots, O_{n_{\\text{heads}}}) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R7GC_ZP8yx3"
      },
      "source": [
        "Useful tips:\n",
        "- You might find the `.view` method useful for splitting and merging heads. Check the [documentation](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) for more details.\n",
        "- You might find the `.contiguous()` method useful for merging heads. Check the [documentation](https://pytorch.org/docs/stable/generated/torch.Tensor.contiguous.html) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv13KL6l8yx3"
      },
      "source": [
        "**You will complete the following code blocks denoted by `TODO:`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4dc9002e93f029e1a5ee8fcbd94953fe",
          "grade": false,
          "grade_id": "cell-6f76a75118763d8f",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "TWAfpL2d8yx3"
      },
      "outputs": [],
      "source": [
        "def split_heads_qkv(Q, K, V, n_heads: int):\n",
        "    \"\"\"\n",
        "    Provided as a utility -- you can choose to not use it if you'd like.\n",
        "    \"\"\"\n",
        "    print(f\"Before splitting heads - Q: {Q.shape}, K: {K.shape}, V: {V.shape}\")\n",
        "    return (split_heads(Q, n_heads), split_heads(K, n_heads), split_heads(V, n_heads))\n",
        "    print(f\"After splitting heads - Q: {Q_split.shape}, K: {K_split.shape}, V: {V_split.shape}\")\n",
        "\n",
        "\n",
        "def split_heads(x, n_heads: int):\n",
        "    \"\"\"\n",
        "    Splitting x across multiple heads.\n",
        "    Inputs:\n",
        "    - x: torch.Tensor, shape (B, n_tok, n_embd) can be the queries, or keys, or values, where B is the batch size, n_tok is the number of tokens, and n_embd is the embedding dimension.\n",
        "    - n_heads: int, the number of heads.\n",
        "    :return: A split x, shape (B,n_heads, n_tok, n_embd // n_heads)\n",
        "    \"\"\"\n",
        "    B, n_tok, n_embd = x.size()\n",
        "    print(f\"Input tensor shape for splitting: {x.shape}\")\n",
        "    assert n_embd % n_heads == 0, \"d must be divisible by number of heads\"\n",
        "\n",
        "    # Compute the embedding size per head\n",
        "    head_dim = n_embd // n_heads\n",
        "    print(f\"Computed head_dim: {head_dim}\")\n",
        "    #scores /= d_head ** 0.5\n",
        "\n",
        "\n",
        "    # reshape to split embeddings across heads\n",
        "    x = x.view(B, n_tok, n_heads, head_dim)\n",
        "    print(f\"Shape after reshaping for heads: {x.shape}\")\n",
        "\n",
        "    # Transpose to (B, n_heads, n_tok, head_dim)\n",
        "    x = x.transpose(1, 2)\n",
        "    print(f\"Shape after transpose: {x.shape}\")\n",
        "    return x\n",
        "\n",
        "def merge_heads(y):\n",
        "    \"\"\"\n",
        "    Reversing splitting action of y.\n",
        "    Inputs:\n",
        "    - y: torch.Tensor, shape (B, n_heads, n_tok, n_embd // n_heads)\n",
        "    :return: A merged y, shape (B, n_tok, n_embd)\n",
        "    \"\"\"\n",
        "    B, n_heads, n_tok, d_head = y.size()\n",
        "    print(f\"Input tensor shape for merging: {y.shape}\")\n",
        "\n",
        "    # permute the order dimensions\n",
        "    y = y.transpose(1, 2)\n",
        "    print(f\"Shape after transpose for merging: {y.shape}\")\n",
        "\n",
        "    # merge the heads by reshaping\n",
        "    y = y.contiguous().view(B, n_tok, n_heads * d_head)\n",
        "    print(f\"Shape after merging heads: {y.shape}\")\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsNE9mQl8yx3"
      },
      "source": [
        "## Test 3: Adding Multi-Head Attention\n",
        "\n",
        "Implement lines denoted by `Step 3` in `self-attention()`, and run the following test code to verify your implementation produces close enough results to the PyTorch implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfRWrWuY8yx3",
        "outputId": "56cfc08c-dae1-4990-d851-1a7366407087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Shapes - Q: torch.Size([1, 10, 6]), K: torch.Size([1, 10, 6]), V: torch.Size([1, 10, 6])\n",
            "Input tensor shape for splitting: torch.Size([1, 10, 6])\n",
            "Computed head_dim: 2\n",
            "Shape after reshaping for heads: torch.Size([1, 10, 3, 2])\n",
            "Shape after transpose: torch.Size([1, 3, 10, 2])\n",
            "Input tensor shape for splitting: torch.Size([1, 10, 6])\n",
            "Computed head_dim: 2\n",
            "Shape after reshaping for heads: torch.Size([1, 10, 3, 2])\n",
            "Shape after transpose: torch.Size([1, 3, 10, 2])\n",
            "Input tensor shape for splitting: torch.Size([1, 10, 6])\n",
            "Computed head_dim: 2\n",
            "Shape after reshaping for heads: torch.Size([1, 10, 3, 2])\n",
            "Shape after transpose: torch.Size([1, 3, 10, 2])\n",
            "After splitting heads - Q: torch.Size([1, 3, 10, 2]), K: torch.Size([1, 3, 10, 2]), V: torch.Size([1, 3, 10, 2])\n",
            "Raw attention scores shape: torch.Size([1, 3, 10, 10])\n",
            "Scaled attention scores shape: torch.Size([1, 3, 10, 10])\n",
            "Causal mask shape: torch.Size([10, 10])\n",
            "Masked attention scores shape: torch.Size([1, 3, 10, 10])\n",
            "Softmax probabilities shape: torch.Size([1, 3, 10, 10])\n",
            "Weighted sum of values shape: torch.Size([1, 3, 10, 2])\n",
            "Input tensor shape for merging: torch.Size([1, 3, 10, 2])\n",
            "Shape after transpose for merging: torch.Size([1, 10, 3, 2])\n",
            "Shape after merging heads: torch.Size([1, 10, 6])\n",
            "Final output shape: torch.Size([1, 10, 6])\n",
            "max diff: 1.7881393432617188e-07\n"
          ]
        }
      ],
      "source": [
        "######################################################\n",
        "#  The following code is given to you. DO NOT MODIFY.\n",
        "######################################################\n",
        "\n",
        "out_A = self_attention(part1_query, part1_key, part1_value, n_heads=3, causal=True)\n",
        "out_B = MHA_wrapper(part1_query, part1_key, part1_value, n_heads=3, causal=True)\n",
        "assert out_A.shape == out_B.shape == part1_query.shape\n",
        "\n",
        "print(\"max diff:\", (out_A - out_B).abs().max().item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv0Gdie08yx3"
      },
      "source": [
        "The max difference should be very small, our reference implementation gets a difference of the order of 1e-7\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP-jYaN68yx3"
      },
      "source": [
        "## 1.2: Experiment with Your Transformer\n",
        "\n",
        "In this part, you will train a transformer-based language model. We will provide you the starter code for training the model and evaluating perplexity on a dataset. You will then explore changes to the network architecture and see how they affect the training and performance of the language model.\n",
        "\n",
        "**Note: We will NOT grade this part of the assignment.** This is an open-ended exercise. The following codes provide you with a basis to experiment with some perspectives of your attention block, and you will summarize your explorations in the write-up. We will only grade the write-up for part 2.2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0APUT6ki8yx3"
      },
      "source": [
        "## Preparation: Modifications to Your Attention Implementation for section 2.2\n",
        "\n",
        "Below is space for you to work on a *modified* version of your attention implementation above for your experimentation in section 2.2. **Ensure your submitted code does not break the tests in section 2.1**; the easiest way to do this is to *copy* your implementation above (and probably condense it) and modify it below. We provide you pointers on what explorations you can do in the handout.\n",
        "\n",
        "You can also put any code anywhere in section 2.2; putting that code here is just a suggestion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "addddf000a8e7380e6b5ddcaf39dbe4f",
          "grade": false,
          "grade_id": "cell-2834ef85f422e30d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "HNpF2oXu8yx3"
      },
      "outputs": [],
      "source": [
        "def pre_softmax_masking_attention(Q, K, V, mask=None, **kwargs):\n",
        "    \"\"\"\n",
        "    Standard pre-softmax masking attention.\n",
        "    Args:\n",
        "        Q: Queries tensor of shape (B, n_heads, seq_len, d_k)\n",
        "        K: Keys tensor of shape (B, n_heads, seq_len, d_k)\n",
        "        V: Values tensor of shape (B, n_heads, seq_len, d_v)\n",
        "        mask: Mask tensor of shape (B, 1, seq_len, seq_len)\n",
        "    Returns:\n",
        "        Output tensor of shape (B, n_heads, seq_len, d_v)\n",
        "    \"\"\"\n",
        "    d_k = Q.size(-1)\n",
        "    scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
        "    attn_weights = torch.nn.functional.softmax(scores, dim=-1)\n",
        "    output = torch.matmul(attn_weights, V)\n",
        "    return output\n",
        "\n",
        "\n",
        "def post_softmax_zero_masking_attention(Q, K, V, mask):\n",
        "    \"\"\"\n",
        "    Modified post-softmax zero masking attention.\n",
        "    Args:\n",
        "        Q: Queries tensor of shape (B, n_heads, seq_len, d_k)\n",
        "        K: Keys tensor of shape (B, n_heads, seq_len, d_k)\n",
        "        V: Values tensor of shape (B, n_heads, seq_len, d_v)\n",
        "        mask: Mask tensor of shape (B, 1, seq_len, seq_len)\n",
        "    Returns:\n",
        "        Output tensor of shape (B, n_heads, seq_len, d_v)\n",
        "    \"\"\"\n",
        "    d_k = Q.size(-1)\n",
        "    scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
        "    attn_weights = F.softmax(scores, dim=-1)\n",
        "    if mask is not None:\n",
        "        attn_weights = attn_weights * mask\n",
        "    output = torch.matmul(attn_weights, V)\n",
        "    return output\n",
        "\n",
        "\n",
        "# <<<\n",
        "# YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "def split_heads_qkv(Q, K, V, n_heads: int):\n",
        "    \"\"\"\n",
        "    Provided as a utility -- you can choose to not use it if you'd like.\n",
        "    \"\"\"\n",
        "    print(f\"Before splitting heads - Q: {Q.shape}, K: {K.shape}, V: {V.shape}\")\n",
        "    return (split_heads(Q, n_heads), split_heads(K, n_heads), split_heads(V, n_heads))\n",
        "    print(f\"After splitting heads - Q: {Q.shape}, K: {K.shape}, V: {V.shape}\")\n",
        "\n",
        "\n",
        "def split_heads(x, n_heads: int):\n",
        "    \"\"\"\n",
        "    Splitting x across multiple heads.\n",
        "    Inputs:\n",
        "    - x: torch.Tensor, shape (B, n_tok, n_embd) can be the queries, or keys, or values, where B is the batch size, n_tok is the number of tokens, and n_embd is the embedding dimension.\n",
        "    - n_heads: int, the number of heads.\n",
        "    :return: A split x, shape (B,n_heads, n_tok, n_embd // n_heads)\n",
        "    \"\"\"\n",
        "    B, n_tok, n_embd = x.size()\n",
        "    assert n_embd % n_heads == 0, \"d must be divisible by number of heads\"\n",
        "    # TODO:\n",
        "    x = x.view(B, n_tok, n_heads, n_embd // n_heads)\n",
        "    x = x.transpose(1, 2)\n",
        "    return x\n",
        "\n",
        "\n",
        "def merge_heads(y):\n",
        "    \"\"\"\n",
        "    Reversing splitting action of y.\n",
        "    Inputs:\n",
        "    - y: torch.Tensor, shape (B, n_heads, n_tok, n_embd // n_heads)\n",
        "    :return: A merged y, shape (B, n_tok, n_embd)\n",
        "    \"\"\"\n",
        "    B, nh, n_tok, nc = y.size()\n",
        "    # TODO:\n",
        "    y = y.transpose(1, 2)\n",
        "    y = y.contiguous().view(B, n_tok, nh * nc)\n",
        "    return y\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXewZP6P8yx3"
      },
      "source": [
        "## Guideline for Section 1.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyMWEcrq8yx3"
      },
      "source": [
        "What follows is the **starter code** for section 1.2. It includes the following:\n",
        "- Download the ngram data from Project 1\n",
        "- Download the fork of minGPT by Yegor, modified to receive an implementation of attention from an external source (i.e., this notebook)\n",
        "- Simple implementation of tokenization which is very similar to what you did for Project 1. Differences from Project 1:\n",
        "    - include `<START>` in the vocab\n",
        "    - truncate to a fixed maximum sequence length of 100 tokens\n",
        "    - pad with `<PAD>` to the max length\n",
        "- `<PAD>` is new -- the loss is set to ignore anything with this token, such that the model doesn't get optimized for learning how to pad, and instead gets trained for the actual text.\n",
        "- Model initialization is set up, but has not been tuned. Feel free to modify anything about it.\n",
        "- Simple trainer code to loop over the data and optimize on the model. We included a nice progress bar for you to watch while waiting.\n",
        "    - On the free-tier GPU in Colab, our provided starter code trains for an epoch (less than 2000 steps) within a few minutes. On CPU, it takes over an hour for even the smallest configuration.\n",
        "- Demonstration/explanation of loss calculation.\n",
        "- Per-document perplexity calculation like in Project 1, though it's a bit different:\n",
        "    - Due to the max training length, the learned positional embeddings won't extrapolate past 100 tokens. So, we actually only test on a *truncated* version of the data\n",
        "    - Most documents are less than 100 tokens and end up with a long chain of `<PAD>`s at the end. We don't want to include that in our loss/perplexity, so we show how to omit it from the calculation.\n",
        "- minGPT defines a very convenient `generate` function. We have a few example prompts you can try with it -- take a look at the kind of text your trained model generates.\n",
        "\n",
        "----\n",
        "\n",
        "**Feel free to modify the starter code as much as you want to!** We will focus on your report and not your code for section 2.2, so change anything. In particular, you will want to add more analysis/logging/comparisons for anything that's relevant to your experiment. Of course, that is in addition to the changes on top of part 2.1, as needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVBntEaj8yx3"
      },
      "source": [
        "### Utilities, data, and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhizKkpU8yx3",
        "outputId": "2dd069e0-e5fe-4fde-b4cd-1316638415f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--2024-12-08 04:17:16--  https://homes.cs.washington.edu/~kahuja/cse447/project1/data/shakespear_train.txt\n",
            "Resolving homes.cs.washington.edu (homes.cs.washington.edu)... 128.208.3.226, 2607:4000:200:12::e2\n",
            "Connecting to homes.cs.washington.edu (homes.cs.washington.edu)|128.208.3.226|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 943314 (921K) [text/plain]\n",
            "Saving to: ‘data/shakespear_train.txt’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  5%  590K 1s\n",
            "    50K .......... .......... .......... .......... .......... 10% 1.14M 1s\n",
            "   100K .......... .......... .......... .......... .......... 16% 1.24M 1s\n",
            "   150K .......... .......... .......... .......... .......... 21% 15.6M 1s\n",
            "   200K .......... .......... .......... .......... .......... 27% 58.2M 0s\n",
            "   250K .......... .......... .......... .......... .......... 32%  114M 0s\n",
            "   300K .......... .......... .......... .......... .......... 37% 1.27M 0s\n",
            "   350K .......... .......... .......... .......... .......... 43% 18.7M 0s\n",
            "   400K .......... .......... .......... .......... .......... 48% 97.9M 0s\n",
            "   450K .......... .......... .......... .......... .......... 54%  108M 0s\n",
            "   500K .......... .......... .......... .......... .......... 59% 73.5M 0s\n",
            "   550K .......... .......... .......... .......... .......... 65%  103M 0s\n",
            "   600K .......... .......... .......... .......... .......... 70%  130M 0s\n",
            "   650K .......... .......... .......... .......... .......... 75% 1.30M 0s\n",
            "   700K .......... .......... .......... .......... .......... 81% 23.6M 0s\n",
            "   750K .......... .......... .......... .......... .......... 86% 92.0M 0s\n",
            "   800K .......... .......... .......... .......... .......... 92%  155M 0s\n",
            "   850K .......... .......... .......... .......... .......... 97% 90.0M 0s\n",
            "   900K .......... .......... .                               100%  206M=0.3s\n",
            "\n",
            "2024-12-08 04:17:16 (3.52 MB/s) - ‘data/shakespear_train.txt’ saved [943314/943314]\n",
            "\n",
            "--2024-12-08 04:17:16--  https://homes.cs.washington.edu/~kahuja/cse447/project1/data/shakespear_dev.txt\n",
            "Resolving homes.cs.washington.edu (homes.cs.washington.edu)... 128.208.3.226, 2607:4000:200:12::e2\n",
            "Connecting to homes.cs.washington.edu (homes.cs.washington.edu)|128.208.3.226|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 113449 (111K) [text/plain]\n",
            "Saving to: ‘data/shakespear_dev.txt’\n",
            "\n",
            "     0K .......... .......... .......... .......... .......... 45%  535K 0s\n",
            "    50K .......... .......... .......... .......... .......... 90% 1.05M 0s\n",
            "   100K ..........                                            100% 53.9M=0.1s\n",
            "\n",
            "2024-12-08 04:17:16 (791 KB/s) - ‘data/shakespear_dev.txt’ saved [113449/113449]\n",
            "\n",
            "--2024-12-08 04:17:16--  https://homes.cs.washington.edu/~kahuja/cse447/project1/data/shakespear_test.txt\n",
            "Resolving homes.cs.washington.edu (homes.cs.washington.edu)... 128.208.3.226, 2607:4000:200:12::e2\n",
            "Connecting to homes.cs.washington.edu (homes.cs.washington.edu)|128.208.3.226|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 103515 (101K) [text/plain]\n",
            "Saving to: ‘data/shakespear_test.txt’\n",
            "\n",
            "     0K .......... .......... .......... .......... .......... 49%  589K 0s\n",
            "    50K .......... .......... .......... .......... .......... 98% 1.15M 0s\n",
            "   100K .                                                     100% 2.03T=0.1s\n",
            "\n",
            "2024-12-08 04:17:17 (793 KB/s) - ‘data/shakespear_test.txt’ saved [103515/103515]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# We will use the Shakespeare dataset we used in Project 1.\n",
        "mkdir -p data\n",
        "wget https://homes.cs.washington.edu/~kahuja/cse447/project1/data/shakespear_train.txt -O data/shakespear_train.txt\n",
        "wget https://homes.cs.washington.edu/~kahuja/cse447/project1/data/shakespear_dev.txt -O data/shakespear_dev.txt\n",
        "wget https://homes.cs.washington.edu/~kahuja/cse447/project1/data/shakespear_test.txt -O data/shakespear_test.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "ggUPudjR8yx4"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# clone Yegor's fork of minGPT and link to the code\n",
        "[ -d \"mingpt-cse447\" ] || git clone https://gitlab.cs.washington.edu/yegork/mingpt-cse447.git\n",
        "[ -e \"mingpt\" ] || ln -s mingpt-cse447/mingpt mingpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "yxDoFlKd8yx4"
      },
      "outputs": [],
      "source": [
        "from mingpt.model import GPT\n",
        "from mingpt.trainer import Trainer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "from collections import Counter\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4o_bNHd8yx9"
      },
      "source": [
        "### Dataset processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UACeV0w8yx9",
        "outputId": "b3b9c925-ee56-4ee8-fad3-78ecec4bcc41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen : Before we proceed any further , hear me speak .\n",
            "All : Speak , speak .\n",
            "First Citizen : You are all resolved rather to die than to famish ?\n",
            "All : Resolved .\n",
            "resolved .\n",
            "First Citizen : First , you know Caius Marcius is chief enemy to the people .\n",
            "All : We know't , we know't .\n",
            "First Citizen : Let us kill him , and we 'll have corn at our own price .\n",
            "Is't a verdict ?\n",
            "All : No more talking o n't ; let it be done : away , away !\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# recall that our data is just a text file of space-separated tokens, with new lines separating documents\n",
        "cat data/shakespear_train.txt | head -n 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnAeUSr58yx9",
        "outputId": "1d40fffc-9d60-43aa-fd30-b6d61dc514d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train docs: 9875\n",
            "total train tokens: 206589\n"
          ]
        }
      ],
      "source": [
        "with open(\"data/shakespear_train.txt\", \"r\") as f: lines_train = f.readlines()\n",
        "with open(\"data/shakespear_dev.txt\", \"r\") as f: lines_dev = f.readlines()\n",
        "with open(\"data/shakespear_test.txt\", \"r\") as f: lines_test = f.readlines()\n",
        "\n",
        "# each element is a list of tokens\n",
        "tokens_train = [line.split() for line in lines_train]\n",
        "\n",
        "print(f\"train docs: {len(tokens_train)}\")\n",
        "print(f\"total train tokens: {sum(len(t) for t in tokens_train)}\")\n",
        "\n",
        "\n",
        "# utility fn to flatten the tokens structure\n",
        "def flat(tokens):\n",
        "    for t in tokens:\n",
        "        yield from t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU7Vx5wI8yx9",
        "outputId": "be6a5077-84db-4947-e13c-19e62587b5cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique_tokens: 12613\n",
            "unique_tokens, count>=3: 4622\n",
            "sentence='More people have said an Escher sentence than I have .'\n",
            "tokenized=[0, 419, 271, 32, 334, 112, 2, 1174, 97, 8, 32, 6, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "decoded='<START> More people have said an <UNK> sentence than I have . <STOP> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'\n"
          ]
        }
      ],
      "source": [
        "# get counts of each token sorted by count, descending\n",
        "# also add a few special tokens (with high counts) so they appear first\n",
        "token_counts = Counter(flat(tokens_train))\n",
        "token_counts[\"<START>\"] = 1000004\n",
        "token_counts[\"<STOP>\"] = 1000003\n",
        "token_counts[\"<UNK>\"] = 1000002\n",
        "token_counts[\"<PAD>\"] = 1000001\n",
        "sorted_tokens = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"unique_tokens:\", len(token_counts))\n",
        "print(\"unique_tokens, count>=3:\", len([t for t in sorted_tokens if t[1] >= 3]))\n",
        "\n",
        "# make tokenizer for all tokens with count >= 3\n",
        "# note that our tokenizer ends up including START and STOP tokens too\n",
        "tokenizer = {t[0]: i for i, t in enumerate(sorted_tokens) if t[1] >= 3}\n",
        "\n",
        "\n",
        "def pad_to_length(tokens, max_len, tokenizer=tokenizer):\n",
        "    return tokens[:max_len] + [tokenizer[\"<PAD>\"]] * (max_len - len(tokens))\n",
        "\n",
        "\n",
        "def tokenize(sentence, pad_to_len=None, include_stop=True, tokenizer=tokenizer):\n",
        "    words = [tokenizer.get(w, tokenizer[\"<UNK>\"]) for w in sentence.split()]\n",
        "    # add START and STOP tokens\n",
        "    tokens = [tokenizer[\"<START>\"]] + words + ([tokenizer[\"<STOP>\"]] * include_stop)\n",
        "\n",
        "    if pad_to_len is not None:\n",
        "        tokens = pad_to_length(tokens, pad_to_len, tokenizer=tokenizer)\n",
        "    return tokens\n",
        "\n",
        "\n",
        "# invert tokenizer for decoding\n",
        "tokenizer_inv = {v: k for k, v in tokenizer.items()}\n",
        "\n",
        "\n",
        "def decode(tokens, tokenizer_inv=tokenizer_inv, end_at_stop=True, omit_pad=True):\n",
        "    tokens = [tokenizer_inv[t] for t in tokens]\n",
        "    if omit_pad:\n",
        "        tokens = [t for t in tokens if t != \"<PAD>\"]\n",
        "    if end_at_stop and \"<STOP>\" in tokens:\n",
        "        tokens = tokens[: tokens.index(\"<STOP>\") + 1]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "\n",
        "sentence = \"More people have said an Escher sentence than I have .\"\n",
        "tokenized = tokenize(sentence, pad_to_len=25)  # pad to only 25 so it looks nice\n",
        "decoded = decode(tokenized, end_at_stop=False, omit_pad=False)\n",
        "print(f\"{sentence=}\\n{tokenized=}\\n{decoded=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "6GCjtDbr8yx9",
        "outputId": "faf1412d-dcb5-43f2-f411-0c58da5ce05c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.hist([len(t) for t in tokens_train], bins=50)\n",
        "plt.title(\"sequence lengths in the train dataset by tokens\")\n",
        "plt.ylabel(\"# of sequences\")\n",
        "plt.xlabel(\"sequence length in tokens\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsqPFqy48yx9",
        "outputId": "48349b3a-f725-440c-a8ab-f68806f88af5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([9875, 100]), torch.Size([1304, 100]))"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "# Notice above that the vast majority of sequences have less than 100 tokens.\n",
        "# For performance we will thus truncate to 100 tokens.\n",
        "\n",
        "MAX_LEN = 100\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "data_train = torch.tensor(\n",
        "    [tokenize(t, MAX_LEN) for t in lines_train if len(t) > 0], dtype=torch.long\n",
        ")\n",
        "data_val = torch.tensor(\n",
        "    [tokenize(t, MAX_LEN) for t in lines_dev if len(t) > 0], dtype=torch.long\n",
        ")\n",
        "\n",
        "data_train.shape, data_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fXYUdhK8yx-",
        "outputId": "ff8a6174-e725-4f24-b785-98964df3016f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([   0,   99,   50,   15, 1562,   12,  873, 1563,    6,    1,    3,    3,\n",
              "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
              "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
              "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
              "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
              "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
              "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
              "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
              "            3,    3,    3]),\n",
              " tensor([  99,   50,   15, 1562,   12,  873, 1563,    6,    1,    3,    3,    3,\n",
              "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
              "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
              "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
              "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
              "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
              "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
              "            3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
              "            3,    3,    3]))"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "# X is all but last token, Y is all but first token\n",
        "train_dataset = torch.utils.data.TensorDataset(data_train[:, :-1], data_train[:, 1:])\n",
        "val_dataset = torch.utils.data.TensorDataset(data_val[:, :-1], data_val[:, 1:])\n",
        "\n",
        "# example X,Y pair from train dataset -- 2 is <START>, 3 is <STOP>\n",
        "train_dataset[447]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoA5N4Xg8yx-"
      },
      "source": [
        "### Model and Trainer code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYrT8LDD8yx-",
        "outputId": "5458868c-6744-4957-d133-f8888229db45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters: 0.36M\n"
          ]
        }
      ],
      "source": [
        "model_config = GPT.get_default_config()\n",
        "model_config.model_type = None\n",
        "model_config.pad_token = tokenizer[\"<PAD>\"]\n",
        "\n",
        "# This configuration is the very small 'gpt-nano' defined in minGPT. we'd use a\n",
        "# bigger model like 'gpt2' but it would take a very long time to train :(\n",
        "# See minGPT/model.py for configurations of other models\n",
        "model_config.model_type = \"gpt-nano\"\n",
        "# 'gpt-nano' equivalent to:\n",
        "# model_config.n_layer = 3\n",
        "# model_config.n_head = 3\n",
        "# model_config.n_embd = 48\n",
        "\n",
        "model_config.vocab_size = max(tokenizer.values()) + 1\n",
        "# model_config.vocab_size = 50257 # openai's model vocabulary, if using gpt2 BPE\n",
        "\n",
        "# The model's context length\n",
        "# Note that minGPT has learned posemb, so outside the used maxlen wont really work\n",
        "model_config.block_size = 1024\n",
        "\n",
        "# We modified config to accept some functions for attention\n",
        "# Feel free to replace either of these!\n",
        "model_config.attn_init_fn = init_qkv_proj\n",
        "model_config.attn_fn = pre_softmax_masking_attention\n",
        "\n",
        "# Can use the wrapper around PyTorch's multi-head attention instead, but it's hard to modify for experiments\n",
        "# model_config.attn_fn = MHA_wrapper\n",
        "\n",
        "model = GPT(model_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7H1mTnM8yx-",
        "outputId": "f1a0647f-a48a-4988-dcd8-0c2e0f488739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running on device cpu\n"
          ]
        }
      ],
      "source": [
        "train_config = Trainer.get_default_config()\n",
        "train_config.device = DEVICE\n",
        "train_config.num_workers = 2\n",
        "\n",
        "# We didn't tune the hyperparameters at all, feel free to change\n",
        "train_config.learning_rate = 5e-4\n",
        "train_config.batch_size = 32\n",
        "train_config.max_iters = 3 * (\n",
        "    len(train_dataset) // train_config.batch_size\n",
        ")  # train for 3 epochs\n",
        "\n",
        "trainer = Trainer(train_config, model, train_dataset)\n",
        "log = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "013df9764e9148a98a3842b98d34991e",
            "8dada7bb6dd1449bb977554e73fe397b",
            "d5d2b28b5b5f44d2b5138c730baf6233",
            "5c8bb3907c2a4c4dab76ba5a6e7dfa6a",
            "aa173e09c9134ef5a11f547e36c339d7",
            "d3574c6614e149be926f27991dab75f1",
            "9a0b48af08ee49c5933a0f79b0c82b97",
            "60260b1f6bdc4a218e501af87617de31",
            "173cea3dce184e828715bb5c3598cb85",
            "640677cb1d86498ba87a56ca352d6091",
            "23a91bb76e6a4704aad4c4f2a28a8491"
          ]
        },
        "id": "QMSIJ30t8yx-",
        "outputId": "dcba94df-3d3b-410a-fdf5-9b5da40e40a7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/924 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "013df9764e9148a98a3842b98d34991e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.to(DEVICE)\n",
        "model.train()\n",
        "\n",
        "bar = tqdm(total=train_config.max_iters)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def on_batch_end(trainer):\n",
        "    log.append(trainer.loss.item())\n",
        "    bar.set_postfix(loss=trainer.loss.item())\n",
        "    bar.update()\n",
        "\n",
        "\n",
        "trainer.set_callback(\"on_batch_end\", on_batch_end)\n",
        "trainer.run()\n",
        "bar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "iwfut4ny8yx-",
        "outputId": "841217ae-b608-4da7-a609-32c72cd5b057"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(log)\n",
        "plt.xlabel(\"step\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCNxVw8S8yx-"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "Like in Project 1, we will treat each line in the data file as a separate document. So, compute perplexity for each line separately and then take the average across all lines.\n",
        "\n",
        "However, the way we processed our data for batching makes it slightly more complicated, because the loss is averaged over tokens. While this would normally be simple, recall that we insert `<PAD>` tokens as padding until 100 tokens, and the vast majority of documents are significantly less than 100 tokens. This means that most of our tokens are the long tail of `<PAD>`s.\n",
        "\n",
        "So, we wish to exlude every `<PAD>` from perplexity calculations. Since the loss returned by the model is averaged for all tokens. PyTorch has great utilities for excluding a padding token from calculations, but we will also do this manually as a demonstration.\n",
        "\n",
        "However, this isn't the end of the story. Ideally, we would make `<PAD>` tokens have no effect whatsoever. For this to happen, we should apply a mask out all attention to and from `<PAD>` tokens, but we chose not to include that in your required implementation. The fact that we did not implement this has no measurable impact because our minGPT fork zeros out values for `<PAD>` tokens after attention anyway."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYmmRXQp8yx-",
        "outputId": "efbd9277-c93d-48cf-a6cd-ab79a716dca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "notice the long tail of PAD tokens:  [0, 3257, 14, 39, 160, 2, 10, 2, 31, 44, 30, 382, 25, 33, 17, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "\n",
            "reported loss from model:\t 2.501478672027588\n",
            "manually calculated loss:\t 2.501478672027588\n",
            "manually calculated loss again:\t 2.501478672027588\n",
            "perplexity: 12.200521469116211\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Thank you so much Liwei and Taylor for all your help with this !\"\n",
        "\n",
        "tokens = torch.tensor([tokenize(sentence, pad_to_len=MAX_LEN)], dtype=torch.long)\n",
        "X_tokens, y_tokens = tokens[:, :-1], tokens[:, 1:]\n",
        "\n",
        "print(\"notice the long tail of PAD tokens: \", tokens.cpu()[0].tolist())\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits, loss = model(X_tokens.to(DEVICE), y_tokens.to(DEVICE))\n",
        "    logits, loss = logits.cpu(), loss.cpu()\n",
        "\n",
        "# Preprocess logits to unpad -- will be (jagged) list of tensors\n",
        "# We impl looping over them\n",
        "# students have to: convert 1 document's raw logits + y_tokens into loss and ppl\n",
        "\n",
        "# There's more ways to get the loss!\n",
        "\n",
        "# We could use F.cross_entropy with the logits -- this is what the model does\n",
        "# F.cross_entropy can take an \"ignore_index\", which makes it ignore our pad token\n",
        "also_loss = F.cross_entropy(\n",
        "    logits.flatten(0, 1), y_tokens.flatten(0, 1), ignore_index=tokenizer[\"<PAD>\"]\n",
        ")\n",
        "\n",
        "# However, we can just do the calculations manually because we enjoy being perplexed\n",
        "\n",
        "# softmax the logits to get probabilities\n",
        "probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "# work with log of the probabilities for numerical stability\n",
        "log_probs = torch.log(probs)\n",
        "\n",
        "# this is weird pytorch screwery to index into last dimension of log_probs with y_tokens\n",
        "# this selects only the log probabilities of the target tokens\n",
        "y_log_probs = torch.gather(log_probs, -1, y_tokens[..., None])[..., 0]\n",
        "\n",
        "# get all the target log probabilities EXCEPT for when that target token is <PAD>\n",
        "not_pad_y_log_probs = y_log_probs[y_tokens != tokenizer[\"<PAD>\"]]\n",
        "\n",
        "# negative average of the log probs of the target tokens is exactly crossentropy loss here!\n",
        "also_loss_again = -not_pad_y_log_probs.mean()\n",
        "\n",
        "print()\n",
        "print(\"reported loss from model:\\t\", loss.item())\n",
        "print(\"manually calculated loss:\\t\", also_loss.item())\n",
        "print(\"manually calculated loss again:\\t\", also_loss_again.item())\n",
        "\n",
        "# we can calculate perplexity using the crossentropy loss\n",
        "perplexity = torch.exp(also_loss)\n",
        "print(\"perplexity:\", perplexity.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "royCs-ut8yx-"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "We've made a utility function to calculate loss per-document for some data.\n",
        "It accepts a list of strings, tokenizes, evaluates, and returns a list of floats.\n",
        "\"\"\"\n",
        "\n",
        "@torch.no_grad\n",
        "def evaluate_losses(data, model=model, bs=32, progress=True, pad_to_len=MAX_LEN):\n",
        "    it = range(0, len(data), bs)\n",
        "    if progress:\n",
        "        it = tqdm(it)\n",
        "\n",
        "    out = []\n",
        "    for b_start in it:\n",
        "        batch = slice(b_start, b_start + bs)\n",
        "        tokens = torch.tensor(\n",
        "            [tokenize(t, pad_to_len=pad_to_len) for t in data[batch]], dtype=torch.long\n",
        "        ).to(DEVICE)\n",
        "        X_tokens, y_tokens = tokens[:, :-1].contiguous(), tokens[:, 1:].contiguous()\n",
        "\n",
        "        model.eval()\n",
        "        logits, _ = model(X_tokens)\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        y_log_probs = torch.gather(log_probs, 2, y_tokens[..., None])[..., 0]\n",
        "\n",
        "        for i in range(y_tokens.shape[0]):\n",
        "            not_pad = y_tokens[i] != tokenizer[\"<PAD>\"]\n",
        "            loss = -y_log_probs[i, not_pad].mean()\n",
        "            out.append(loss.item())\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i22mZRpP8yx-",
        "outputId": "c0644908-e36f-4f55-c83a-e63965c77de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 2.682979106903076\n",
            "perplexity: 14.628608634239509\n"
          ]
        }
      ],
      "source": [
        "# calculate loss and perplexity for a single sentence\n",
        "is_this_loss = evaluate_losses(\n",
        "    [\n",
        "        \"RICHARD II : I will not be afraid of death . I will not be afraid of death .\",\n",
        "    ],\n",
        "    progress=False,\n",
        ")[0]\n",
        "print(\"loss:\", is_this_loss)\n",
        "print(\"perplexity:\", np.exp(is_this_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "8cf3ac70c9704b50b8c80a5d7e1dc7ab",
            "0ca39cc982a5462ea590f0db43ddb823",
            "9cbda1bf6f1c487ebd1d84122d34e6b6",
            "728e79d883144cc48e04d05151a2ca89",
            "63fadedd74fa4c7db64096e1c6c26836",
            "39b52d66837348ae9f2d864258dbb98b",
            "179bb90fd1444146bf20f013a07eba9b",
            "0351a04608b94a8fb4ebfd888742e2b0",
            "15fa0ce466314a8f9808686de277882e",
            "c6d9f1a399eb4389884ec77a673bfbfd",
            "dc6431b9219b4f7aabe554adadc0fd62"
          ]
        },
        "id": "grgtLbBM8yx-",
        "outputId": "7f1fa78e-3be0-4909-c5dc-cfa684014f0b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/309 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cf3ac70c9704b50b8c80a5d7e1dc7ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train perplexity: 33.25163653101409\n"
          ]
        }
      ],
      "source": [
        "train_losses = evaluate_losses(lines_train)\n",
        "print(\"train perplexity:\", np.mean(np.exp(train_losses)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "bf3dc7a059264910a4650a24a6e69c44",
            "92bae3cf63f74ab39d70a207124b1566",
            "7e456dbd830c4172ac9e09d4dc74a039",
            "f5750f9a58644048a0860ad003c60db9",
            "5e45757b5c044c17ab0ff0897c7d9b7f",
            "467f80ba9d1747fe8b04c40f4946299c",
            "d117866be78d4f4bbdc33ae197a5e390",
            "e0284c850c744ab18587ca87cb2239df",
            "e7e0742d2aae42519d7b34ef9406cd0e",
            "524252132bfe49698ab9df7f7dd9750a",
            "0bf91b553c4a415abf5636cf5607ceb2"
          ]
        },
        "id": "msGZd0Bq8yx-",
        "outputId": "1448d5ea-976d-4de0-ab98-ffe708cbbe1d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/41 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf3dc7a059264910a4650a24a6e69c44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev perplexity: 25.099603314231384\n"
          ]
        }
      ],
      "source": [
        "dev_losses = evaluate_losses(lines_dev)\n",
        "print(\"dev perplexity:\", np.mean(np.exp(dev_losses)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGO2Xoi88yx-"
      },
      "source": [
        "With the implementation on attention in Part 1, you should see that dev perplexity is close to the best perplexities that we achieved using N-gram models and interpolation in Project 1. The reason we don't do much better is that we are using a very small dataset and not doing much tuning. Transformer LMs become much more powerful when we have a whole lot of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51JJ3_zB8yx-"
      },
      "source": [
        "Your task now is to make modifications to the attention mechanisms based on the guidelines in the handout and explore the effects of these changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTqoRrzf8yx_",
        "outputId": "6f1b7b4a-3938-409a-d3ef-227962f2385a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<START> 'll : DUKE DUKE OF ? <STOP>\n",
            "<START> -- You Run sins mark With Within Great weary Her when thou thou thou Romeo minute perpetual heart sir looks thou ? <STOP>\n",
            "<START> OF YORK of of of that Tybalt which traitors glory parents walls . <STOP>\n",
            "<START> First well what your this fain Buckingham Say Wherefore wind Seize young a his deposed prosperity rash yoke odd blood made his mercy unto him enmity from victory with any pride not Wiltshire , Love some hands be raven infected wives 'd speed respect on wont . <STOP>\n",
            "<START> Clown LEONTES 't he he thou points Verona theirs Exeter scouts cushion Citizens hanging if never for so be Hermione turn it while God then did fully bosom ? <STOP>\n",
            "<START> DUKE OF POMPEY HERMIONE frank they it you you not be For for was golden impose ? <STOP>\n",
            "<START> KING divine according bleed prays Caius peevish my I I I I then pardon ten faces doubt I I , to he made either for't I came will how die traitors : I tell I do I know I am we please you see you purchase well rather be I comes you do I 'll do occasion ? <STOP>\n",
            "<START> BOLINGBROKE YORK , , Will with to of of through jocund dread Whither 'fore CLEOMENES of of many downright Having Live several election remedy nor glad such greets in lamentation where how branch 'd by subtle of Didst offended power of fares The foil hours in instant ; Save The extreme acknowledge of joy of title of witness in reverend since MARGARET , race put 'd in EDWARD ; tear 'd laid of man to NORTHUMBERLAND ; A requite ; His ability At flat next hid at crept purpose 'd bigger been of Down ; plead , Their other\n",
            "<START> PRINCE tent ten appear Duke morning yet and And That which manhood Troy fires familiar ignorant 't And So curses less served long deed purpose , We else rabble twice My back But Like longer Shall hast mine holy prince lords that man , My <UNK> that grave and lack and so proper hands and now my blood and majesty and run citizens course and their good but mad other tongue but more men impose thoughts : quarrel left Plantagenet I cry and command arrived and news and sway : Not name as thou early man she speak May\n",
            "<START> CAPULET BOLINGBROKE ports fliers ballad valiant an shadows aloof confidence BUCKINGHAM Senator Tybalt Prince Greece stain misery ignorance giving lowly shrift conscience patricians male fighting Banish leader nightingale Mariner Exeter general wast earthly CARLISLE broke straight refuge wanting purple cast a Gentleman nest midnight me us quarrel maintain move Surrey hollow Bona untimely ashes sing impediment fiery carries others Love salt wring sole Still Scotland general behind him meant sides Hie afford courtesy HENRY VI Servant command bred me tale suffer amity ride me seeming renown by special excuse LARTIUS : Therefore promised how heap me tragic requires Mantua\n"
          ]
        }
      ],
      "source": [
        "# Here's an example of generating using the model -- see generate in minGPT's model.py\n",
        "\n",
        "sentence = \"\"  # empty prompt -> sample from model at random\n",
        "# sentence = 'unfortunately ,'          # can sample more negative stuff\n",
        "# sentence = 'fun fact : did you know'  # AI-generated fun facts\n",
        "\n",
        "tokens = torch.tensor([tokenize(sentence, include_stop=False)], dtype=torch.long).to(\n",
        "    DEVICE\n",
        ")\n",
        "\n",
        "for _ in range(10):\n",
        "    pred = model.generate(\n",
        "        tokens, MAX_LEN - tokens.shape[-1], temperature=1.0, do_sample=True, top_k=None\n",
        "    )\n",
        "\n",
        "    print(decode(pred[0].tolist()))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "013df9764e9148a98a3842b98d34991e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dada7bb6dd1449bb977554e73fe397b",
              "IPY_MODEL_d5d2b28b5b5f44d2b5138c730baf6233",
              "IPY_MODEL_5c8bb3907c2a4c4dab76ba5a6e7dfa6a"
            ],
            "layout": "IPY_MODEL_aa173e09c9134ef5a11f547e36c339d7"
          }
        },
        "8dada7bb6dd1449bb977554e73fe397b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3574c6614e149be926f27991dab75f1",
            "placeholder": "​",
            "style": "IPY_MODEL_9a0b48af08ee49c5933a0f79b0c82b97",
            "value": "100%"
          }
        },
        "d5d2b28b5b5f44d2b5138c730baf6233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60260b1f6bdc4a218e501af87617de31",
            "max": 924,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_173cea3dce184e828715bb5c3598cb85",
            "value": 924
          }
        },
        "5c8bb3907c2a4c4dab76ba5a6e7dfa6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_640677cb1d86498ba87a56ca352d6091",
            "placeholder": "​",
            "style": "IPY_MODEL_23a91bb76e6a4704aad4c4f2a28a8491",
            "value": " 924/924 [07:19&lt;00:00,  2.35it/s, loss=3.88]"
          }
        },
        "aa173e09c9134ef5a11f547e36c339d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3574c6614e149be926f27991dab75f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a0b48af08ee49c5933a0f79b0c82b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60260b1f6bdc4a218e501af87617de31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "173cea3dce184e828715bb5c3598cb85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "640677cb1d86498ba87a56ca352d6091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23a91bb76e6a4704aad4c4f2a28a8491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cf3ac70c9704b50b8c80a5d7e1dc7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ca39cc982a5462ea590f0db43ddb823",
              "IPY_MODEL_9cbda1bf6f1c487ebd1d84122d34e6b6",
              "IPY_MODEL_728e79d883144cc48e04d05151a2ca89"
            ],
            "layout": "IPY_MODEL_63fadedd74fa4c7db64096e1c6c26836"
          }
        },
        "0ca39cc982a5462ea590f0db43ddb823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39b52d66837348ae9f2d864258dbb98b",
            "placeholder": "​",
            "style": "IPY_MODEL_179bb90fd1444146bf20f013a07eba9b",
            "value": "100%"
          }
        },
        "9cbda1bf6f1c487ebd1d84122d34e6b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0351a04608b94a8fb4ebfd888742e2b0",
            "max": 309,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15fa0ce466314a8f9808686de277882e",
            "value": 309
          }
        },
        "728e79d883144cc48e04d05151a2ca89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6d9f1a399eb4389884ec77a673bfbfd",
            "placeholder": "​",
            "style": "IPY_MODEL_dc6431b9219b4f7aabe554adadc0fd62",
            "value": " 309/309 [01:04&lt;00:00,  5.82it/s]"
          }
        },
        "63fadedd74fa4c7db64096e1c6c26836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39b52d66837348ae9f2d864258dbb98b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "179bb90fd1444146bf20f013a07eba9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0351a04608b94a8fb4ebfd888742e2b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15fa0ce466314a8f9808686de277882e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6d9f1a399eb4389884ec77a673bfbfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc6431b9219b4f7aabe554adadc0fd62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf3dc7a059264910a4650a24a6e69c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92bae3cf63f74ab39d70a207124b1566",
              "IPY_MODEL_7e456dbd830c4172ac9e09d4dc74a039",
              "IPY_MODEL_f5750f9a58644048a0860ad003c60db9"
            ],
            "layout": "IPY_MODEL_5e45757b5c044c17ab0ff0897c7d9b7f"
          }
        },
        "92bae3cf63f74ab39d70a207124b1566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_467f80ba9d1747fe8b04c40f4946299c",
            "placeholder": "​",
            "style": "IPY_MODEL_d117866be78d4f4bbdc33ae197a5e390",
            "value": "100%"
          }
        },
        "7e456dbd830c4172ac9e09d4dc74a039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0284c850c744ab18587ca87cb2239df",
            "max": 41,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7e0742d2aae42519d7b34ef9406cd0e",
            "value": 41
          }
        },
        "f5750f9a58644048a0860ad003c60db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_524252132bfe49698ab9df7f7dd9750a",
            "placeholder": "​",
            "style": "IPY_MODEL_0bf91b553c4a415abf5636cf5607ceb2",
            "value": " 41/41 [00:08&lt;00:00,  5.51it/s]"
          }
        },
        "5e45757b5c044c17ab0ff0897c7d9b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "467f80ba9d1747fe8b04c40f4946299c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d117866be78d4f4bbdc33ae197a5e390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0284c850c744ab18587ca87cb2239df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7e0742d2aae42519d7b34ef9406cd0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "524252132bfe49698ab9df7f7dd9750a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf91b553c4a415abf5636cf5607ceb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}